# DistributedProcessWatcher
<p>Fully distributed asynchronous highly-available Process Monitoring library, specially useful when there are multiple processes that need to be running continuously or data loss might occur. For example, consider a scenario where data is appended to a log file, and we want to store landing data to analyze later with some tool from hadoop ecosystem.</p>

<p>We'd need at least a program monitoring changes to the file and later send this changes to hadoop. Flume would be an useful tool since with an Exec source, we could tail -F the file, send them through a memory channel and use a hdfs sink to persist data. If for some reason (and this is just an example) flume dies, we're gonna stop getting data from the log. With this Process Watcher, we can easily achieve automatic re-deploy of flume and keep getting data from the log.</p><br/>

<b>How does it work?</b>
<p>It comprises three main components: time masters (TM), master watchers (parent: MW and child: CMW) and process wrappers (PW). There's some sort of hierarchy amongst these components, in the sense that MWs rely on TMs to work, CMWs rely on MWs for coordination and on PWs for spawning processes. In order to achieve coordination and synchronization, all components depend on <a href="https://zookeeper.apache.org/">Apache ZooKeeper</a>. TMs and MWs have an <b>autonomous Active Master (ATM or AMW) election</b> feature, that is, they compete against each other to see which TM or MW becomes the next ATM or AMW. The rest of the masters are inactive masters (ITM or IMW). Now, ITMs and IMWs have to monitor that the current ATM or AMW is online and that it is doing its job. If for any reason, an ATM or AMW stops responding (that is, reporting its health status to its peers inactive masters), inactive masters will start a new competition after following a <a href="#sdp">Safety Deletion Policy (for Time Masters)</a> or <a href="#sdpmw">Safety Deletion Policy (for Master Watchers)</a>, to see which ITM or IMW is the next active master.</p>
<p><i>Components explained</i></p>
<ul>
  <li><b>Time Masters:</b> Top level masters requesting time from NTP servers and providing them to lower level components. Competition for active mastership consists of creating a time znode, and the instance that manages to create this instance becomes the ATM. When deploying TMs, the user must indicate two znodes. The first one called <i>time znode</i> (AKA time masters' keep alive znode), where ATM pushes heartbeat according to the time interval provided, and ITMs verify that it is pushing heartbeats within specified threshold. The other znode is called <i>znode for time listeners</i>, used by lower level masters to get time. For high availability, deploy TMs in diferent servers.<br/>
  <b>Class:</b> org.jc.zk.dpw.TimeMaster</li>
  <li><b>Master Watchers:</b> A MW can be one of two types, parent (normally referred to as MW only) or child MW. The reason for having two types of masters is to allow distributed components, that is, a MW can have many CMWs and they can be deployed in different nodes, and CMWs are the one spawning the processes that must remain running most of the time, and must be restarted if anything brings them down. Unlike MWs, CMWs do not have an active CMW election feature so in order to achieve high availability, more than one MW must be deployed and a CMW linked to each of the MWs must be deployed. For example, say you have 4 MWs (mw1, mw2, mw3, mw4), and 2 different processes that must be monitored, you would then deploy 8 CMWs like this (cmw1 linked to mw1; cmw1 linked to mw2; cmw1 linked to mw3; cmw1 linked to mw4; cmw2 linked to mw1; cmw2 linked to mw2; cmw2 linked to mw3; cmw2 linked to mw4). That way, if mw1 is elected as active master, cmw1 and cmw2 linked to mw1 trigger; if for some reason mw1 dies, and mw4 becomes the new active master, cmw1 and cmw2 linked to mw4 will trigger. Now, even though there are 8 cmws, since they all deploy the same process, all of them must have the same id, but the MW they are linked to, will vary in each copy. 
<br/>
MWs do have the autonomous election feature, and if IMWs detect that current active MW is failing to push heartbeat updates, they compete against each other to have a new active MW. To see which MW is the next AMW, all MWs try to create the <b>znode for time listeners</b>. The MW that creates this znode first, becomes the AMW, while the rest remain as IWMs. After receiving the first time tick, AMW creates the znode <b>masters' keep alive znode</b>, where it will push heartbeat updates and IMWs will use it to verify AMW's status, and the <b>process observed znode</b>, which will cause CMWs to spawn processes that must be monitored. Every time the ATM pushes a new time tick, after the initialization is done, the AMW will request CMWs to report their health statuses, and as it gets a report from its children, it will append it to a queue. When the queue is full, the AMW will clear the queue and post an update to master's keep alive znode. If some CMWs fail to report their health statuses, they will be appended to a failing children list, after receiving a warning, when they become critical, AMW will kill itself and all of its children, condition which will be detected by IMWs and after following the <a href="#sdp">Safety Deletion Policy</a>, they will compete against each other. The whole process repeats as many times as there are failing AMW and available IMWs.<br/>
<b>Class:</b> org.jc.zk.dpw.Master</li>
<li><b>Child Master Watcher:</b> In conjuction with a Process Wrapper, CMWs spawn processes. They are linked to a specific instance of a MW and respond to its events. When the MW creates a <b>process observed znode</b>, the CMW that is linked to that MW creates a new process which needs to extend Process Wrapper in order to communicate with the CMW and fulfill its requirements. Each CMW has an assigned <b>update znode</b>, that it must update within time constraints so that its parent MW knows that it is still alive. The <b>update znode</b> has a metadata indicating whether the parent MW is requesting an update or it is intending to kill its CMW. At the same time, when the CMW detects that an <b>update znode</b> was created by the AMW, it creates a heartbeat znode, which must be updated by Process Wrapper before timer expires (timer &lt; time MW can wait for updates from CMW). How long the AMW waits for updates from CMWs depend on the user, but it should be selected such that the interval between ATM's time ticks covers the 2-level updates (PW to CMW; CMW to AMW) for all deployed CMWS (i.e. normally time tick interval divided by number of CMWs with different identifiers).<br/>
Additionaly, there's a currently unused flag, which indicates whether the CMW is active or not. In the future, each cmw gets a failover copy, which would set the <b>activeChild</b> flag to false, so that when the initially active child (<b>activeChild</b> set to true) fails to push updates to AMW, instead of making the AMW kill itself, the AMW will just signal the ACMW to kill itself, yielding to the creation of a <b>failover znode</b>, which the inactive CMW will detect and will change its status from inactive to active. As it was mentioned, this is a future work and left for contributors.<br/>
<b>Class:</b> org.jc.zk.dpw.Master (with child flag set to true)</li>.
<li><b>Process Wrapper:</b> Base class for all processes that must be spawned. Right now, available only for java. It provides hooks to communicate with the CMW that owns it. <br/>
<b>Class:</b> org.jc.zk.process.ProcessWrapper<li>
<br/>
<b>Arguments for each Master</b>
<ul>
  <li><b>Time Master:</b> Use the class org.jc.zk.dpw.TimeHandlerMain for launching an instance of TM with the following arguments.<br/>
  <b>/path/to/java -cp /path/to/DPW.jar org.jc.zk.dpw.TimeHandlerMain uniqueIdentifier zkHost zkPort zkTimeNode zkTimeListenersNode intervalMillis ntpserver1,ntpserver2 amwKillZnode</b><br/>
  <ul>
  <li>uniqueIdentifier: unique identifier for the TM.</li>
  <li>zkHost: Zookeeper host ip address.</li>
  <li>zkPort: ZooKeeper host port.</li>
  <li>zkTimeNode: ZooKeeper znode for time masters' keep alive znode.</li>
  <li>zkTimeListenersNode: ZooKeeper znode for time listeners, where ATM will push time ticks.</li>
  <li>intervalMillis: time interval in milliseconds between time ticks. This should be large enough to cover the 2 level updates mentioned earlier, that is, PW to CMW and CMW to AMW.</li>
  <li>ntpserver1,ntpserver2: list of NTP servers separated by comma.</li>
  <li>amwKillZnode: pre-existing znode that IMWs will use to request permission to kill an inactive AMW.</li>
  </ul></li>
  <li><b>Master Watcher:</b> Use the class org.jc.zk.dpw.MasterWatcherHandlerMain for launching an instanc of MW with the following arguments.<br/>
  <b>/path/to/java -cp /path/to/DPW.jar org.jc.zk.dpw.MasterWatcherHandlerMain uniqueId zkHost zkPort zkTimeListenerZnode zkKeepAliveZnode zkProcessObservedZnode /absolute/path/program/to/run arg1,arg2,...,argn isChild isActiveChild numberOfChildren intervalToWaitForUpdate childUpdateZnode1,childUpdateZnode2... znodeToCreateForUpdate ntpServer1,ntpServer2 idOfParentMasterWatcher maxForgiveMeMillis amwKillZnode</b><br/>
  <ul>
  <li>uniqueId: unique identifier for this instance of MW.</li>
  <li>zkHost: Zookeeper host ip address.</li>
  <li>zkPort: ZooKeeper host port.</li>
  <li>zkTimeListenerNode: ZooKeeper znode for time listeners, where ATM will push time ticks. This must match the one used when deploying TM.</li>
  <li>zkKeepAliveZnode: ZooKeeper znode for master watchers' keep alive znode.</li>
  <li>zkProcessObservedZnode: ZooKeeper znode created by AMW to signal CMWs to deploy their Process Wrappers.</li>
  <li>/absolute/path/program/to/run: absolute path to the process that must be spawned. It must extend ProcessWrapper class. If this refers to an instance of MW, it is set to null (use null keyword, do not leave blank). If this is an instance of CMW, it must have a value different from keyword null.</li>
  <li>arg1,arg2,...,argn: args separated by comma for the process that must be spawned. If this is an instance of MW, it is set to keyword null (not blank). If it is an instance of CMW, it must have a value different from keyword null.</li>
  <li>isChild: flag that indicates whether this is an instance of MW (use false) or an instance of CMW (use true).</li>
  <li>isActiveChild: flag that is currently unused (future work) but it would help identify if an instance of a CMW is an active copy or a failover copy (true or false, respectively). This would avoid an AMW having to kill itself and instead just kill the failing active CMW which would be detected by the failover copy and yield to its status change from isActiveChild false to true. By default, always set to true.</li>
  <li>numberOfChildren: how many different CMWs are deployed. If this is an instance of CMW, set to 0. Remember that even though there's a cmw linked to every MW, this counts as 1 CMW. As a general rule, CMWs with same process to spawn, have the same identifier and count as 1, with the only difference between them being <b>idOfParentMasterWatcher</b>.</li>
  <li>intervalToWaitForUpdate: Depending on the type of instance, MW or CMW, this has different values. If this refers to an instance of MW, it would be the number of milliseconds to wait for the updates queue to fill up before assuming that one or more CMWs are failing. The ideal value is a number slightly smaller than <b>time ticks interval</b> used by TMs. When this refers to an instance of CMW, it is the number of milliseconds that the CMW will wait for its Process Wrapper to push an update to heartbeat znode; the ideal value would be <b>time ticks interval</b> used in TMs divided by the <b>numberOfChildren</b> minus a small number of milliseconds. <b>PERFORM ALL CALCULATIONS WHEN DEPLOYING THE MASTER, DO NOT DO IT DYNAMICALLY INSIDE THE CODE.</b></li>
  <li>childUpdateZnode1,childUpdateZnode2...: list of update znodes separated by comma. If this refers to an instance of MW, this is the list of znodes the AMW will create when it needs to receive health status reports from CMWs, and as each CMW updates its assigned update znode, it will enqueue the updates until the updates queue becomes full and later push an update to <b>zkKeepAliveZnode</b>. If this refers to an instance of CMW, it is just used for control.</li>
  <li>znodeToCreateForUpdate: ZooKeeper znode assigned to a CMW that it must update to push health status updates. If this refers to an instance of MW, just set to keyword null. If this refers to a CMW, use a znode that exists in the list of update znodes provided earlier.</li>
  <li>ntpServer1,ntpServer2: list of NTP servers separated by comma.</li>
  <li>idOfParentMasterWatcher: identifier of the MW a CMW is linked to. If this refers to an instance of MW, this value matches its <b>uniqueId</b>.</li>
  <li>maxForgiveMeMillis: how many milliseconds will IMWs wait before competing for a new election after the current AMW fails to update multiple times. This should be larger than <b>time ticks interval</b> used for TMs.</li>
  <li>hardKillScript: provide a combination of command plus script to hard kill processes. This is necessary if you consider that a process.destroy() won't suffice. This script will be executed when the active CMW is told to kill itself.</li>  
  <li>amwKillZnode: pre-existing znode that IMWs use to request permission to kill inactive AMW and also to check whether they got permission or not.</li>
  </ul></li>
</ul><br/>

<b id="sdp">Safety Deletion Policy (for Time Masters)</b>
<p>Before proceeding to a competition for new active TM, inactive TMs must follow a safety deletion policy:</p>
<ul>
  <li>Masters must wait a specified amount of milliseconds before proceeding to the creation of a notification znode.</li>
  <li>Only masters that finished waiting and still have time to create notification znode, can participate in the competition.</li>
  <li>The only master that managed to create the notification znode, is the next active master.</li>
  <li>Masters that did not compete for creating notification znode, just wait until allowed-to-compete masters finish competition.</li>
  </ul><br/>

<b id="sdpmw">Safety Deletion Policy (for Master Watchers)</b>
<p>When IMWs detect that current AMW is not responding on time, they have to find a new AMW that will keep processes
running. Unlike TMs, IMWs must request for permission to proceed with a competition (and thus, permission to kill AMW).
Permission can be granted by the current ATM, and the first thing an IMW does is check what the current status of AMW kill request znode is.
If it is FREE, it requests permission to kill AMW and become the next AMW. If the ATM grants permission, it sets the znode
to BUSY and proceeds to become the new ATM. After a while, ATM restores the status of AMW kill request znode and sets it back to FREE.</p>

<b>Why is there a need of a Safety Deletion Policy?</b>
<p>Even though znodes are automatically removed when a client disconnects, we cannot always assume that once an ATM or AMW stops responding, it will also disconnect from ZooKeeper. So this deletion policy, forces ITMs or IMWs to verify whether a critical znode for the correct operation of the library has been removed before proceeding to compete for a new ATM or AMW. Imagine that there are 3 MWs: mw1, mw2 and mw3; and mw1 stops responding but it does not disconnect from ZooKeeper. Znode for time listeners and keep alive znode continue to exist, but mw2 is the first MW to detect that current AMW is failing to update within time. So, if they do not follow the deletion policy, and they just remove existing znodes before re-creating those 2 critical znodes for the operation of MWs, mw3 might delete the znode that mw2 created seconds before it also detected that mw1 was failing to update, and this would lead to a new unnecessary competition, discarding an IMW that could have kept the system running if 2 MWs were gone. </p>
<p>So, by following the safety policy, we avoid having situations where unnecessary competitions take place and things continue to work as expected.</p>
